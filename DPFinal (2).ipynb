{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import scipy.signal as ss\n",
    "import scipy.optimize as opt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axisartist.parasite_axes import HostAxes, ParasiteAxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Test data\n",
    "txt_Data = \"sample.txt\"\n",
    "xv = np.linspace(0, 2*np.pi, 500)\n",
    "yv = 5*np.sin(xv)\n",
    "ye = np.ones(500)/100\n",
    "z = np.matrix([xv, yv, ye]).T\n",
    "np.savetxt(txt_Data, z, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def loadDat(txt_Data):\n",
    "    '''Read data from .dat file [time, volume]'''\n",
    "    # Parameters\n",
    "    mass_error = 0.01 # g\n",
    "    p = 998.2336 # Density of water\n",
    "    p_error = 0.0001 # Error in density\n",
    "    \n",
    "    # load data file\n",
    "    dat = np.loadtxt(txt_Data)\n",
    "    \n",
    "    \n",
    "    error = np.ones(len(dat)) # Generate array of error values\n",
    "    data = np.zeros([len(dat), 3]) # Initialise output data array\n",
    "    # Set up data array [t, v=m/p, v uncertainty]\n",
    "    for i in range(len(dat)):\n",
    "        error = (dat[i,1]/(p*10**3))*np.sqrt((mass_error/dat[i,1])**2+(p_error/p)**2)\n",
    "        data[i,0] = dat[i,0]/1000\n",
    "        data[i,1] = dat[i,1]/(p*10**3)\n",
    "        data[i,2] = error\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# defines model object\n",
    "class models:\n",
    "    \"\"\"Containes model functions and params (with initialiser)\"\"\"\n",
    "    def __init__(self):\n",
    "        self.float_Chi2 = 0\n",
    "    \n",
    "    ##########Define models here###########\n",
    "    def polynomial(self, arr_X, arr_Vals):\n",
    "        '''Polynumial model input x and values'''\n",
    "        float_Y = 0.0\n",
    "        for i in range(self.int_N):\n",
    "            float_Y += arr_Vals[i]*arr_X**i\n",
    "        return float_Y\n",
    "    \n",
    "    def harmonic(self, arr_X, arr_Vals):\n",
    "        '''a*sin(b*x)+d*cos(e*x) model input x and values'''\n",
    "        s = arr_Vals[0]*np.sin(arr_Vals[1]*arr_X)\n",
    "        c = arr_Vals[2]*np.cos(arr_Vals[3]*arr_X)\n",
    "        return s + c\n",
    "    #######################################    \n",
    "    \n",
    "    def initVals(self, int_N):\n",
    "        '''Initialiser for the parameters to be optimised for the model'''\n",
    "        self.arr_Vals = np.random.rand(int_N)\n",
    "        self.float_UnVal = np.random.rand(int_N)\n",
    "        \n",
    "    def setMod(self, mod, params):\n",
    "        '''Initialises the users chosem model type'''\n",
    "        if mod == 0:\n",
    "            # Polynomial model with params[0] number of parameters\n",
    "            self.initVals(self, params[0])\n",
    "            self.int_N = params[0] # Degree of polynomial\n",
    "            self.f = self.polynomial\n",
    "        if mod == 1:\n",
    "            self.initVals(self, 4)\n",
    "            self.f = self.harmonic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def Chi2(arr_Vals, model, data):\n",
    "    '''Chi^2 calculation'''\n",
    "    float_Top = data[:,1]-model.f(model, data[:,0], arr_Vals)\n",
    "    float_Chi = np.sum(np.power((float_Top/data[:,2]),2))\n",
    "    return float_Chi\n",
    "\n",
    "def Chi2a1(float_Val, model, data, fixIndx):\n",
    "    '''Chi^2 modification function allowing all but one variable \n",
    "    to be manipulated by the optimiser used for Step 1 of algorithm \n",
    "    from lab session 2'''\n",
    "    # Fills in the arr_Valls with the fixed parameter and all the free ones\n",
    "    arr_Vals = model.arr_Vals\n",
    "    arr_Vals[fixIndx] = float_Val # Replaces the value in arr_vals with the fixed value\n",
    "    Chi = Chi2(arr_Vals, model, data)\n",
    "    # Is optimised when Chi^2 calculated here approaches minimised Chi^2 + 1\n",
    "    return abs(Chi - model.float_Chi2 - 1)\n",
    "\n",
    "def Chi3(arr_Val, model, data, freeIndx):\n",
    "    '''Chi^2 modification function allowing only one variable \n",
    "    to be manipulated by the optimiser used for Step 2 of algorithm \n",
    "    from lab session 2'''\n",
    "    arr_Vals = model.arr_Vals\n",
    "    arr_Vals[freeIndx] = arr_Val # Replaces the value in arr_vals with the free values\n",
    "    Chi = Chi2(arr_Vals, model, data)\n",
    "    # Is optimised when Chi^2 is minimised\n",
    "    return Chi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def UncIndv(model, data, fixIndx):\n",
    "    '''Performs iterative chi^2 uncertainty calculation'''\n",
    "    arr_Vals = np.copy(model.arr_Vals) # initialise value array\n",
    "    # Free index = [1,2,...,n-1,n+1,...m] where fixIndex = n\n",
    "    freeIndx = np.delete(np.arange(0, len(arr_Vals), 1), fixIndx)  \n",
    "    for i in range(10):\n",
    "        # Step 1\n",
    "        # Optimisation function\n",
    "        dict_Unc1 = opt.minimize(Chi2a1,\n",
    "                                   arr_Vals[fixIndx],\n",
    "                                   method='nelder-mead',\n",
    "                                   args=(model, data, fixIndx))\n",
    "        \n",
    "        # gets output from the optimisation\n",
    "        arr_Vals[fixIndx] = dict_Unc1.x\n",
    "        #Step 2\n",
    "        # Optimisation function\n",
    "        dict_Unc2 = opt.minimize(Chi3,\n",
    "                                   arr_Vals[freeIndx],\n",
    "                                   method='nelder-mead',\n",
    "                                   args=(model, data, freeIndx))\n",
    "        \n",
    "        # gets output from the optimisation\n",
    "        arr_Vals[freeIndx] = dict_Unc1.x\n",
    "    \n",
    "    # Perform Step 1 again to end on odd number\n",
    "    # Optimisation function\n",
    "    dict_Unc1 = opt.minimize(Chi2a1,\n",
    "                           arr_Vals[fixIndx],\n",
    "                           method='nelder-mead',\n",
    "                           args=(model, data, fixIndx))\n",
    "    return dict_Unc1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def Uncertainty(model, data):\n",
    "    '''Uncertainty is calculated (iteratively0 using the method from lab session 2'''\n",
    "    uncert = np.copy(model.arr_Vals) # Prevents overriding the memory\n",
    "    for i in range(len(uncert)):\n",
    "        uncert[i] -= UncIndv(model, data, i)\n",
    "    return abs(uncert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def Resid(arr_Vals, model, data):\n",
    "    '''Calculates the residuals given a model with model params and data'''\n",
    "    resid = np.ones(len(data))\n",
    "    resid = (data[:,1] - model.f(model, data[:,0], arr_Vals))/data[:,2]  \n",
    "    return resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def linResid(arr_Vals, data):\n",
    "    resid = np.ones(len(data[0]))\n",
    "    resid = (data[1] - [arr_Vals[0]]*len(data[0]) - arr_Vals[1]*data[0])\n",
    "    return resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def DW(residuals):\n",
    "    '''Calculates the Durbin_Watson statistic given an array of residuals'''\n",
    "    num = 0\n",
    "    for i in range(1, len(residuals)):\n",
    "        num += (residuals[i]-residuals[i-1])**2\n",
    "    den = np.sum(residuals**2)\n",
    "    return num/den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e860ae10843e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Input the data file below. Ensure the path is local\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadDat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./Black/490.dat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-80a38f7705ad>\u001b[0m in \u001b[0;36mloadDat\u001b[0;34m(txt_Data)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# load data file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt_Data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/src36/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)\u001b[0m\n\u001b[1;32m    966\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/src36/lib/python3.6/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/src36/lib/python3.6/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    621\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    622\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: ./Black/490.dat not found."
     ],
     "ename": "OSError",
     "evalue": "./Black/490.dat not found.",
     "output_type": "error"
    }
   ],
   "source": [
    "# Optimises a model v(t) for a given data file\n",
    "# The second parameter output corresponds to the gradient\n",
    "# dv/dt with the associated uncertainty\n",
    "# Input the data file below. Ensure the path is local\n",
    "#################################\n",
    "data = loadDat(\"./Black/490.dat\")\n",
    "#################################\n",
    "\n",
    "# Initialise model\n",
    "obj_Model = models\n",
    "obj_Model.setMod(obj_Model, 0, [2])\n",
    "\n",
    "# Optimise model\n",
    "dict_Result = opt.minimize(Chi2,\n",
    "                           obj_Model.arr_Vals,\n",
    "                           method='nelder-mead',\n",
    "                           args=(obj_Model, data))\n",
    "\n",
    "# Storing model data\n",
    "obj_Model.arr_Vals = dict_Result.x\n",
    "obj_Model.float_Chi2 = dict_Result.fun\n",
    "obj_Model.float_UnVal = Uncertainty(obj_Model, data)\n",
    "\n",
    "# Output results\n",
    "print(\"Chi^2: \", obj_Model.float_Chi2)\n",
    "print(\"DOF: \", len(data) - len(obj_Model.arr_Vals))\n",
    "print(\"Reduced Chi^2: \", obj_Model.float_Chi2/(len(data) - len(obj_Model.arr_Vals)))\n",
    "print(\"parameters:\")\n",
    "for i in range(len(obj_Model.arr_Vals)):\n",
    "    print(\"    \", obj_Model.arr_Vals[i], \"+-\", obj_Model.float_UnVal[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Plots valume against time for the model and the data\n",
    "# Generates t values for model\n",
    "x = np.linspace(np.amin(data[:,0]), np.amax(data[:,0]), 100)\n",
    "plt.plot(data[:,0], data[:,1], color='b', label='Data') # Data\n",
    "plt.scatter(data[:,0], data[:,1], color='b')\n",
    "plt.plot(x, obj_Model.f(obj_Model, x, obj_Model.arr_Vals), color='r', label='Model') # Model\n",
    "plt.xlabel('time $(s)$')\n",
    "plt.ylabel('volume $(m^3)$')\n",
    "plt.title(\"Expelled volume of water against time\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Plots the normalised residuals for the desired sample\n",
    "res = Resid(obj_Model.arr_Vals, obj_Model, data)\n",
    "plt.xlabel(\"time $(s)$\")\n",
    "plt.ylabel(\"Normalised residual\")\n",
    "plt.title(\"Normalised residuals\")\n",
    "plt.plot(data[:,0], res)\n",
    "plt.scatter(data[:,0], res)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "peaks = ss.find_peaks(res)\n",
    "t = []\n",
    "for i in range(len(peaks[0])-1):\n",
    "    t.append(peaks[0][i+1]-peaks[0][i])\n",
    "avrT = np.average(t)\n",
    "print(avrT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Calculates viscosity using two methods; from the gradient of (h, dv/dt) graph\n",
    "# and from average value of 1/h*dv/dt (CALC1 and CALC2 respectively).\n",
    "# Record data as h.dat where h is in 10^(-4)m\n",
    "# Input the directory corresponding the the desired data set\n",
    "# Ensure that the selected directory is in the same folder as this script\n",
    "######################\n",
    "directory = 'Red1'\n",
    "######################\n",
    "\n",
    "# Parameters used to calculate viscosity\n",
    "tubeParams = {'Black': [15.2*10**(-2), 1.03*10**(-3), 0.04*10**(-3)],\n",
    "             'Red1': [14.1*10**(-2), 0.471*10**-3, 0.006*10**(-3)],\n",
    "             'Blue': [15.2*10**(-2), 0.814*10**(-3), 0.01*10**(-3)]}\n",
    "\n",
    "hUnc = 0.075*10**(-2) # Uncertainty in height measurements\n",
    "a = tubeParams[directory][1:3]\n",
    "p = [998.2336, 0.0001]\n",
    "g = [9.81, 0.1]\n",
    "l = [tubeParams[directory][0], 0.71*10**(-2)]\n",
    "pi = [np.pi, 0]\n",
    "var = np.array([a,p,g,l,pi])\n",
    "\n",
    "\n",
    "# Accepted viscosity\n",
    "accVisc = 1.002*10**(-3)\n",
    "accViscUnc = 0.0001*10**(-3)\n",
    "\n",
    "# Initialise model for finding volume v(t)\n",
    "obj_Model_1 = models\n",
    "obj_Model_1.setMod(obj_Model_1, 0, [2])\n",
    "\n",
    "# Array initialisation for for loop\n",
    "gradH = []\n",
    "data_hdvdt = []\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    # Load data\n",
    "    data = loadDat(os.path.join(directory, file))\n",
    "    \n",
    "    obj_Model_1.initVals(obj_Model_1, 2)\n",
    "    \n",
    "    # Optimise fit\n",
    "    dict_Result = opt.minimize(Chi2,\n",
    "                           obj_Model_1.arr_Vals,\n",
    "                           method='nelder-mead',\n",
    "                           args=(obj_Model_1, data)) # Optimisation function\n",
    "    \n",
    "    # Degrees of freedom calculation\n",
    "    DOF = len(data) - len(obj_Model_1.arr_Vals)\n",
    "    \n",
    "    # Assign optimised values to model object variables\n",
    "    obj_Model_1.float_Chi2 = dict_Result.fun\n",
    "    obj_Model_1.arr_Vals = dict_Result.x\n",
    "    \n",
    "    # Determines h from file name\n",
    "    h = float(file[:len(file)-3])/10000 #- 1.6*10**(-2)\n",
    "    \n",
    "    grad = dict_Result.x[1]\n",
    "    gradUn = Uncertainty(obj_Model_1, data)[1] # Gradient uncertainty calculation\n",
    "    gradHUn = (grad/h)*((gradUn/grad)**2 + (hUnc/h)**2)**0.5 # Gradient/h\n",
    "    \n",
    "    # Appends values required later to arrays\n",
    "    gradH.append([grad/h, gradHUn]) # Contains 1/h*dv/dt and uncertainty used in CALC2\n",
    "    data_hdvdt.append([h, grad, gradUn]) # Contains height, dv/dt and uncertainty used in CALC1\n",
    "    \n",
    "    # Output and plot\n",
    "    # Used to plot volume against time see below also\n",
    "    '''\n",
    "    plt.plot(data[:,0], obj_Model_1.f(obj_Model_1, data[:,0], obj_Model_1.arr_Vals))\n",
    "    plt.errorbar(data[:,0], data[:,1], yerr=data[:,2], ms=50)\n",
    "    '''\n",
    "    print('Height:', np.around(h, decimals=3), ' DOF:', DOF, ' Reduced Chi^2:', dict_Result.fun/DOF)\n",
    "\n",
    "# Clear new line in output\n",
    "print(\"\")\n",
    "    \n",
    "# Convert arrays to np arrays for slicing\n",
    "gradH = np.array(gradH)\n",
    "data_hdvdt1 = np.array(data_hdvdt)\n",
    "\n",
    "\n",
    "                    ###CALC1###\n",
    "    \n",
    "# Calculate viscosity from gradient of (h, dv/dt)\n",
    "# Begin by performing chi^2 analysis on the (h, dv/dt) plot\n",
    "obj_Model_hdvdt1 = models\n",
    "obj_Model_hdvdt1.setMod(obj_Model_hdvdt1, 0, [2])\n",
    "dict_Result_hdvdt1 = opt.minimize(Chi2,\n",
    "                           obj_Model_hdvdt1.arr_Vals,\n",
    "                           method='nelder-mead',\n",
    "                           args=(obj_Model_hdvdt1, data_hdvdt1)) # Optimisation function\n",
    "\n",
    "# Getting values from the minimisation class\n",
    "obj_Model_hdvdt1.float_Chi2 = dict_Result_hdvdt1.fun\n",
    "obj_Model_hdvdt1.arr_Vals = dict_Result_hdvdt1.x\n",
    "\n",
    "grad_hdvdt1 = dict_Result_hdvdt1.x[1] # Gradient as calculated with chi^2\n",
    "gradUn_hdvdt1 = Uncertainty(obj_Model_1, data_hdvdt1)[1] # Uncertainty as calculated by Chi^2\n",
    "\n",
    "# Calcualte the viscosity\n",
    "viscosity_hdvdt1 = (pi[0]*p[0]*g[0]*a[0]**4)/(grad_hdvdt1*8*l[0])\n",
    "\n",
    "# Uncertainty calculation\n",
    "temp = np.sum((var[:,1]/var[:,0])**2) + 3*(var[0,1]/var[0,0])**2 + (gradUn_hdvdt1/grad_hdvdt1)**2\n",
    "viscosity_hdvdt1_unc = viscosity_hdvdt1*np.sqrt(temp)\n",
    "\n",
    "# Goodness of fit\n",
    "compError = (viscosity_hdvdt1-accVisc)/viscosity_hdvdt1_unc\n",
    "\n",
    "# Output\n",
    "red1Vals = obj_Model_hdvdt1.arr_Vals\n",
    "print(\"Reduced Chi^2 for fitting (h, dv/dt): \", dict_Result_hdvdt1.fun/6)\n",
    "print(\"viscosity from gradient: \", viscosity_hdvdt1, \"+-\", viscosity_hdvdt1_unc, \"Pa\")\n",
    "print('Goodness of fit:', compError, 'sigma', '\\n')\n",
    "\n",
    "                    ###CALC1###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Calculates viscosity using two methods; from the gradient of (h, dv/dt) graph\n",
    "# and from average value of 1/h*dv/dt (CALC1 and CALC2 respectively).\n",
    "# Record data as h.dat where h is in 10^(-4)m\n",
    "# Input the directory corresponding the the desired data set\n",
    "# Ensure that the selected directory is in the same folder as this script\n",
    "######################\n",
    "directory = 'Black'\n",
    "######################\n",
    "\n",
    "# Parameters used to calculate viscosity\n",
    "tubeParams = {'Black': [15.2*10**(-2), 1.03*10**(-3), 0.04*10**(-3), 0, 'k'],\n",
    "             'Red': [14.1*10**(-2), 0.471*10**-3, 0.006*10**(-3), 1, 'r'],\n",
    "             'Blue': [15.2*10**(-2), 0.814*10**(-3), 0.01*10**(-3), 2, 'b']}\n",
    "\n",
    "# Initialise array of output values\n",
    "viscAndUnc = np.empty([len(tubeParams), 2])\n",
    "res = np.empty([len(tubeParams), 10, 50])\n",
    "avrT = np.empty([len(tubeParams), 10])\n",
    "stdT = np.empty([len(tubeParams), 10])\n",
    "sumCompError = 0\n",
    "\n",
    "# Initialise figure\n",
    "g1 = 1 # (h, dv/dt)\n",
    "g2 = 2 # (h, residuals)\n",
    "g3 = 0 # (h, drop volume)\n",
    "fig = plt.figure(figsize=[8,10])\n",
    "gs = gridspec.GridSpec(3, 1)\n",
    "gs.update(wspace=0.0, hspace=0.0)\n",
    "axes = [fig.add_subplot, fig.add_subplot, fig.add_subplot]\n",
    "\n",
    "axes[1] = fig.add_subplot(gs[1])\n",
    "axesSub = plt.axes([0.185, 0.52, 0.2, 0.1])\n",
    "axesSub.set_ylim(bottom=0.55, top=0.7)\n",
    "axesSub.set_xlim(left=0.06, right=0.08)\n",
    "axes[0] = fig.add_subplot(gs[0], sharex=axes[1])\n",
    "axes[2] = fig.add_subplot(gs[2], sharex=axes[1])\n",
    "plt.xlabel('Height / $m$')\n",
    "axes[g1].set_ylabel('$dv/dt$ / $mm^3 s^{-1}$')\n",
    "axes[g2].set_ylabel('log transformed normalised residuals')\n",
    "axes[g3].set_ylabel('Drip volume / $mm^{3}$')\n",
    "plt.setp(axes[g1].get_xticklabels(), visible=False)\n",
    "plt.setp(axes[g3].get_xticklabels(), visible=False)\n",
    "axes[g3].set_ylim(-5, 45)\n",
    "axes[g3].spines['right'].set_visible(False)\n",
    "axes[g3].spines['top'].set_visible(False)\n",
    "axes[g1].spines['right'].set_visible(False)\n",
    "axes[g2].spines['right'].set_visible(False)\n",
    "\n",
    "for countDir, directory in enumerate(tubeParams):\n",
    "    print('Tube:', directory)\n",
    "    hUnc = 0.075*10**(-2) # Uncertainty in height measurements\n",
    "    a = tubeParams[directory][1:3]\n",
    "    p = [998.2336, 0.0001]\n",
    "    g = [9.81, 0.1]\n",
    "    l = [tubeParams[directory][0], 0.71*10**(-2)]\n",
    "    pi = [np.pi, 0]\n",
    "    var = np.array([a,p,g,l,pi])\n",
    "\n",
    "    # Accepted viscosity\n",
    "    accVisc = 1.002*10**(-3)\n",
    "    accViscUnc = 0.0001*10**(-3)\n",
    "\n",
    "    # Initialise model for finding volume v(t)\n",
    "    obj_Model_1 = models\n",
    "    obj_Model_1.setMod(obj_Model_1, 0, [2])\n",
    "\n",
    "    # Array initialisation for for loop\n",
    "    gradH = []\n",
    "    data_hdvdt = []\n",
    "    chi_10 = np.array([])\n",
    "\n",
    "    for countFile, file in enumerate(os.listdir(directory)):\n",
    "        # Load data\n",
    "        data = loadDat(os.path.join(directory, file))\n",
    "\n",
    "        obj_Model_1.initVals(obj_Model_1, 2)\n",
    "\n",
    "        # Optimise fit\n",
    "        dict_Result = opt.minimize(Chi2,\n",
    "                               obj_Model_1.arr_Vals,\n",
    "                               method='nelder-mead',\n",
    "                               args=(obj_Model_1, data)) # Optimisation function\n",
    "\n",
    "        # Degrees of freedom calculation\n",
    "        DOF = len(data) - len(obj_Model_1.arr_Vals)\n",
    "\n",
    "        # Assign optimised values to model object variables\n",
    "        obj_Model_1.float_Chi2 = dict_Result.fun\n",
    "        obj_Model_1.arr_Vals = dict_Result.x\n",
    "        \n",
    "        # Fill chi_10 with each of the 10 chi^2 values for each file\n",
    "        chi_10 = np.append(chi_10, obj_Model_1.float_Chi2)\n",
    "\n",
    "        # Residual analysis\n",
    "        res[countDir, countFile] = Resid(obj_Model_1.arr_Vals, obj_Model_1, data)\n",
    "        peaks = ss.find_peaks(res[countDir, countFile])\n",
    "        t = []\n",
    "        for i in range(len(peaks[0])-1):\n",
    "            t.append(peaks[0][i+1]-peaks[0][i])\n",
    "        avrT[countDir, countFile] = np.average(t)\n",
    "        stdT[countDir, countFile] = np.std(t)\n",
    "\n",
    "        \n",
    "        # Determines h from file name\n",
    "        h = float(file[:len(file)-3])/10000 #- 1.6*10**(-2)\n",
    "\n",
    "        grad = dict_Result.x[1]\n",
    "        gradUn = Uncertainty(obj_Model_1, data)[1] # Gradient uncertainty calculation\n",
    "        gradHUn = (grad/h)*((gradUn/grad)**2 + (hUnc/h)**2)**0.5 # Gradient/h\n",
    "\n",
    "        # Appends values required later to arrays\n",
    "        gradH.append([grad/h, gradHUn]) # Contains 1/h*dv/dt and uncertainty used in CALC2\n",
    "        data_hdvdt.append([h, grad, gradUn]) # Contains height, dv/dt and uncertainty used in CALC1\n",
    "\n",
    "        # Output and plot\n",
    "        # Used to plot volume against time see below also\n",
    "        '''\n",
    "        plt.plot(data[:,0], obj_Model_1.f(obj_Model_1, data[:,0], obj_Model_1.arr_Vals))\n",
    "        plt.errorbar(data[:,0], data[:,1], yerr=data[:,2], ms=50)\n",
    "        '''\n",
    "        \n",
    "        # Output data for each file\n",
    "        print('Height:', np.around(h, decimals=3), ' DOF:', DOF, ' Reduced Chi^2:', dict_Result.fun/DOF)\n",
    "        sumCompError += dict_Result.fun/DOF\n",
    "\n",
    "    # Clear new line in output\n",
    "    print(\"\")\n",
    "\n",
    "    # Convert arrays to np arrays for slicing\n",
    "    gradH = np.array(gradH)\n",
    "    data_hdvdt = np.array(data_hdvdt)\n",
    "\n",
    "\n",
    "                        ###CALC1###\n",
    "\n",
    "    # Calculate viscosity from gradient of (h, dv/dt)\n",
    "    # Begin by performing chi^2 analysis on the (h, dv/dt) plot\n",
    "    obj_Model_hdvdt = models\n",
    "    obj_Model_hdvdt.setMod(obj_Model_hdvdt, 0, [2])\n",
    "    dict_Result_hdvdt = opt.minimize(Chi2,\n",
    "                               obj_Model_hdvdt.arr_Vals,\n",
    "                               method='nelder-mead',\n",
    "                               args=(obj_Model_hdvdt, data_hdvdt)) # Optimisation function\n",
    "\n",
    "    # Getting values from the minimisation class\n",
    "    obj_Model_hdvdt.float_Chi2 = dict_Result_hdvdt.fun\n",
    "    obj_Model_hdvdt.arr_Vals = dict_Result_hdvdt.x\n",
    "\n",
    "    grad_hdvdt = dict_Result_hdvdt.x[1] # Gradient as calculated with chi^2\n",
    "    gradUn_hdvdt = Uncertainty(obj_Model_1, data_hdvdt)[1] # Uncertainty as calculated by Chi^2\n",
    "\n",
    "    # Calcualte the viscosity\n",
    "    viscosity_hdvdt = (pi[0]*p[0]*g[0]*a[0]**4)/(grad_hdvdt*8*l[0])\n",
    "\n",
    "    # Uncertainty calculation\n",
    "    temp = np.sum((var[:,1]/var[:,0])**2) + 3*(var[0,1]/var[0,0])**2 + (gradUn_hdvdt/grad_hdvdt)**2\n",
    "    viscosity_hdvdt_unc = viscosity_hdvdt*np.sqrt(temp)\n",
    "\n",
    "    # Goodness of fit\n",
    "    compError = (viscosity_hdvdt-accVisc)/viscosity_hdvdt_unc\n",
    "    chi_hdvdt = dict_Result_hdvdt.fun\n",
    "    \n",
    "    # Append results to array\n",
    "    viscAndUnc[tubeParams[directory][3]] = [viscosity_hdvdt, viscosity_hdvdt_unc]\n",
    "    \n",
    "    # Output\n",
    "    print(\"Reduced Chi^2 for fitting (h, dv/dt): \", chi_hdvdt/8)\n",
    "    print(\"viscosity from gradient: \", viscosity_hdvdt, \"+-\", viscosity_hdvdt_unc, \"Pa\")\n",
    "    print('Goodness of fit:', compError, 'sigma', '\\n')\n",
    "\n",
    "                        ###CALC1###\n",
    "\n",
    "\n",
    "                        ###CALC2###\n",
    "\n",
    "    # Calculate viscosity from average 1/h*dv/dt\n",
    "    # Calculate average of (1/h)*dV/dt with uncertainty\n",
    "    avGradH = np.average(gradH[:,0]) # gradH[:,0] are 1/h*dv/dt values\n",
    "    avGradHUn = (np.sqrt(np.sum(gradH[:1]**2))/np.sum(gradH))*avGradH # gradH[:,1] are uncertainties in 1/h*dv/dt values\n",
    "\n",
    "    # Viscosity calculation\n",
    "    viscosity = (pi[0]*p[0]*g[0]*a[0]**4)/(8*l[0]*avGradH)\n",
    "\n",
    "    # Uncertainty calculation\n",
    "    temp = np.sum((var[:,1]/var[:,0])**2) + 3*(var[0,1]/var[0,0])**2 + (avGradHUn/avGradH)**2\n",
    "    viscosityUn = viscosity*np.sqrt(temp)\n",
    "\n",
    "    # Goodness of fit\n",
    "    compError = (viscosity-accVisc)/viscosityUn\n",
    "    \n",
    "    # Output\n",
    "    print('Viscosity from average:', viscosity, '+-', viscosityUn, 'Pa')\n",
    "    print('Goodness of fit:', compError, 'sigma')\n",
    "\n",
    "                        ###CALC2###\n",
    "\n",
    "\n",
    "    # Used to view the plots of volume against time see above also\n",
    "    '''\n",
    "    plt.xlabel(\"Time / $s$\")\n",
    "    plt.ylabel(\"Water Voulme / $m^3$\")\n",
    "    '''\n",
    "    \n",
    "    # PLOTTING\n",
    "    # Plot dv/dt against h\n",
    "    hdvdtModel = 10**7*obj_Model_hdvdt.f(obj_Model_hdvdt,\n",
    "                                                data_hdvdt[:,0],\n",
    "                                                obj_Model_hdvdt.arr_Vals)\n",
    "\n",
    "    #axes[g1].plot(data_hdvdt[:,0], 10**4*data_hdvdt[:,1], color=tubeParams[directory][4], label='Data') # Data\n",
    "    axes[g1].errorbar(data_hdvdt[:,0], 10**7*data_hdvdt[:,1], yerr=data_hdvdt[:,2],\n",
    "                      color=tubeParams[directory][4], label='Data', fmt='.')\n",
    "    axes[g1].plot(data_hdvdt[:,0], hdvdtModel, color='grey', label='Model', alpha=0.75, linestyle='--') # Model\n",
    "    if directory == 'Red':\n",
    "        l = len(data_hdvdt)\n",
    "        axesSub.plot(data_hdvdt[l-5:l,0], 10**7*data_hdvdt[l-5:l,1], color=tubeParams[directory][4])\n",
    "\n",
    "    # Plot drop period\n",
    "    area = chi_10/20\n",
    "    # Error is taken to be the percentage error in the avrT\n",
    "    errorV = np.sqrt((stdT[countDir]/avrT[countDir])**2)*avrT[countDir]*hdvdtModel\n",
    "    #axes[g3].plot(data_hdvdt[:,0], avrT[countDir]*hdvdtModel, color=tubeParams[directory][4])\n",
    "    axes[g3].scatter(data_hdvdt[:,0], avrT[countDir]*hdvdtModel,\n",
    "                    s=area,\n",
    "                    alpha=0.5,\n",
    "                    color=tubeParams[directory][4])\n",
    "    axes[g3].errorbar(data_hdvdt[:,0], avrT[countDir]*hdvdtModel, yerr=errorV, color=tubeParams[directory][4], fmt='.')\n",
    "    \n",
    "    # Get DW for the chi^2 against height and drip volume\n",
    "    arrDripsChi = st.linregress(avrT[countDir]*hdvdtModel, area)\n",
    "    linRes = linResid([arrDripsChi[1], arrDripsChi[0]], [avrT[countDir]*hdvdtModel, area])\n",
    "    print('DW drip volume:', DW(linRes))\n",
    "    \n",
    "    # Plot normalised residuals\n",
    "    if directory == 'Red':\n",
    "        res_hdvdt = Resid(red1Vals, obj_Model_hdvdt1, data_hdvdt1)\n",
    "        axes[g2].scatter(data_hdvdt1[:,0], (np.sign(res_hdvdt)*np.log(abs(res_hdvdt)+1)),\n",
    "                     color=tubeParams[directory][4], s=30, marker='x')\n",
    "        print('DW Red1 dv/dt against h:', DW(res_hdvdt))\n",
    "    res_hdvdt = Resid(obj_Model_hdvdt.arr_Vals, obj_Model_hdvdt, data_hdvdt)\n",
    "    axes[g2].scatter(data_hdvdt[:,0], (np.sign(res_hdvdt)*np.log(abs(res_hdvdt)+1)),\n",
    "                     color=tubeParams[directory][4], s=30, marker='.')\n",
    "\n",
    "    print('DW dv/dt against h:', DW(res_hdvdt))\n",
    "    print('Average \\chi^2:', sumCompError/10)\n",
    "    sumCompError=0\n",
    "    print('\\n')\n",
    "    \n",
    "    #axes[g2].hist(res_hdvdt, bins=4, density=True,\n",
    "    #              color=tubeParams[directory][4],\n",
    "    #             alpha=0.25,\n",
    "    #             orientation='horizontal')\n",
    "\n",
    "#Draw reference line on residual plot\n",
    "axes[g2].plot([0.02, 0.1], [0, 0], linestyle='--', color='grey', alpha=0.75)\n",
    "one = np.array([1,1])\n",
    "axes[g2].plot([0.02, 0.1], (np.sign(one)*np.log(abs(one)+1)),\n",
    "              linestyle='--', color='grey', alpha=0.75)\n",
    "axes[g2].plot([0.02, 0.1], (np.sign(-one)*np.log(abs(-one)+1)),\n",
    "              linestyle='--', color='grey', alpha=0.75)\n",
    "\n",
    "# Calculates average viscosity\n",
    "avVisc = np.average(viscAndUnc[:,0])\n",
    "# Calculates uncertainty in average viscosity\n",
    "uncAvVisc = avVisc*(np.sqrt(np.sum(viscAndUnc[:,1]**2))/np.sum(viscAndUnc[:,0]))\n",
    "\n",
    "# Calculates compartive error in number of standard deviations\n",
    "compError = (avVisc-accVisc)/uncAvVisc\n",
    "\n",
    "# Output results\n",
    "print('Average')\n",
    "print('Average Viscosity:', avVisc, '+-', uncAvVisc, 'Pa')\n",
    "print('Goodness of fit:', compError, 'sigma')\n",
    "\n",
    "plt.xlim([0.023,0.09])\n",
    "plt.plot()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Calculates average viscosity\n",
    "# Populate array with viscosity and uncertainty for each tube\n",
    "#viscAndUnc = np.array([[0.0010854513730798512, 6.496738072504902e-05],\n",
    "#                      [0.0035071062467488512, 0.00019659333640224117],\n",
    "#                      [0.0021392328905156317, 0.00019805147418198288]])\n",
    "\n",
    "# Calculates average viscosity\n",
    "avVisc = np.average(viscAndUnc[:,0])\n",
    "# Calculates uncertainty in average viscosity\n",
    "uncAvVisc = avVisc*(np.sqrt(np.sum(viscAndUnc[:,1]**2))/np.sum(viscAndUnc[:,0]))\n",
    "\n",
    "# Calculates compartive error in number of standard deviations\n",
    "compError = (avVisc-accVisc)/uncAvVisc\n",
    "\n",
    "# Output results\n",
    "print('Viscosity:', avVisc, '+-', uncAvVisc, 'Pa')\n",
    "print('Goodness of fit:', compError, 'sigma')\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}